{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Subsets of Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Invocation\n",
    "Example batch command. The second argument is a notebook where the output will be stored. You can load it to see progress.\n",
    "\n",
    "UPDATE EXAMPLE INVOCATION\n",
    "\n",
    "\n",
    "```\n",
    "papermill Wikidata\\ Useful\\ Files.ipynb useful-files.out.ipynb \\\n",
    "-p wiki_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/all.tsv.gz \\\n",
    "-p label_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/part.label.en.tsv.gz \\\n",
    "-p item_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/part.wikibase-item.tsv.gz \\\n",
    "-p property_item_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/part.property.wikibase-item.tsv.gz \\\n",
    "-p qual_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/qual.tsv.gz \\\n",
    "-p output_path <local folder> \\\n",
    "-p output_folder useful_files_v4 \\\n",
    "-p temp_folder temp.useful_files_v4 \\\n",
    "-p delete_database no \\\n",
    "-p compute_pagerank no \\\n",
    "-p languages es,ru,zh-cn \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Folder on local machine where to create the output and temporary folders\n",
    "output_path = \"/data/amandeep\"\n",
    "\n",
    "# The names of the output and temporary folders\n",
    "output_folder = \"wikidata-20210215-dwd\"\n",
    "temp_folder = \"temp.wikidata-20210215-dwd\"\n",
    "\n",
    "# Classes to remove\n",
    "remove_classes = \"Q591041,Q523,Q318,Q7318358,Q7187,Q11173,Q8054\"\n",
    "\n",
    "# The location of input files\n",
    "wiki_root_folder = \"/data/amandeep/wikidata-20210215/\"\n",
    "\n",
    "claims_file = \"claims.tsv.gz\"\n",
    "label_file = \"labels.en.tsv.gz\"\n",
    "alias_file = \"aliases.en.tsv.gz\"\n",
    "description_file = \"descriptions.en.tsv.gz\"\n",
    "item_file = \"claims.wikibase-item.tsv.gz\"\n",
    "qual_file = \"qualifiers.tsv.gz\"\n",
    "property_datatypes_file = \"metadata.property.datatypes.tsv.gz\"\n",
    "metadata_types_file = \"metadata.types.tsv.gz\"\n",
    "isa_file = \"derived.isa.tsv.gz\"\n",
    "p279star_file = \"derived.P279star.tsv.gz\"\n",
    "\n",
    "# Location of the cache database for kypher\n",
    "cache_path = \"/data/amandeep/temp.wikidata-20210215-dwd\"\n",
    "\n",
    "# Whether to delete the cache database\n",
    "### Needs fixing\n",
    "delete_database = \"no\"\n",
    "if delete_database and delete_database.lower().strip() == 'yes':\n",
    "    delete_database = True\n",
    "else:\n",
    "    delete_database = False\n",
    "\n",
    "compute_pagerank = \"yes\"\n",
    "### Needs fixing\n",
    "if compute_pagerank and compute_pagerank.lower().strip() == 'yes':\n",
    "    compute_pagerank = True\n",
    "else:\n",
    "    compute_pagerank = False\n",
    "\n",
    "# shortcuts to commands\n",
    "kgtk = \"time kgtk --debug\"\n",
    "# kgtk = \"kgtk --debug\"\n",
    "\n",
    "# Useful files Jupyter notebook\n",
    "useful_files_notebook = \"Wikidata Useful Files.ipynb\"\n",
    "notebooks_folder = \"/data/amandeep/Github/kgtk/use-cases/\"\n",
    "\n",
    "languages = \"en,ru,es,zh-cn,de,it,nl,pl,fr,pt,sv\"\n",
    "if languages:\n",
    "    languages = languages.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up variables for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cache_path:\n",
    "    os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(cache_path)\n",
    "else:\n",
    "    os.environ['STORE'] = \"{}/{}/wikidata.sqlite3.db\".format(output_path, temp_folder)\n",
    "    \n",
    "if cache_path:\n",
    "    store = \"{}/wikidata.sqlite3.db\".format(cache_path)\n",
    "else:\n",
    "    store = \"{}/{}/wikidata.sqlite3.db\".format(output_path, temp_folder)\n",
    "\n",
    "out = \"{}/{}\".format(output_path, output_folder)\n",
    "temp = \"{}/{}\".format(output_path, temp_folder)\n",
    "\n",
    "kypher = \"kgtk query --debug --graph-cache \" + store\n",
    "\n",
    "claims = wiki_root_folder + claims_file\n",
    "items = wiki_root_folder + item_file\n",
    "isa = wiki_root_folder + isa_file\n",
    "quals = wiki_root_folder + qual_file\n",
    "datatypes = wiki_root_folder + property_datatypes_file\n",
    "metadata_types = wiki_root_folder + metadata_types_file\n",
    "p279star = wiki_root_folder + p279star_file\n",
    "\n",
    "labels = wiki_root_folder + label_file\n",
    "aliases = wiki_root_folder + alias_file\n",
    "descriptions = wiki_root_folder + description_file\n",
    "\n",
    "\n",
    "kgtk_path = \"/data/amandeep/Github/kgtk\"\n",
    "os.environ[\"EXAMPLES_DIR\"] = kgtk_path + \"/examples\"\n",
    "os.environ[\"USECASE_DIR\"] = kgtk_path + \"/use-cases\"\n",
    "os.environ['TEMP'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the output directory and create the subfolders for the output files and the temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/amandeep\n"
     ]
    }
   ],
   "source": [
    "cd $output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {out}\n",
    "!mkdir -p {temp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the output and temp folders before we start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delete_database:\n",
    "    !rm {out}/*.tsv {out}/*.tsv.gz\n",
    "    !rm {temp}/*.tsv {temp}/*.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good practice to peek a the files to make sure the column headings are what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "P10-P1628-32b85d-7927ece6-0\tP10\tP1628\t\"http://www.w3.org/2006/vcard/ns#Video\"\tnormal\turl\n",
      "P10-P1628-acf60d-b8950832-0\tP10\tP1628\t\"https://schema.org/video\"\tnormal\turl\n",
      "P10-P1629-Q34508-bcc39400-0\tP10\tP1629\tQ34508\tnormal\twikibase-item\n",
      "P10-P1659-P1651-c4068028-0\tP10\tP1659\tP1651\tnormal\twikibase-property\n",
      "P10-P1659-P18-5e4b9c4f-0\tP10\tP1659\tP18\tnormal\twikibase-property\n",
      "P10-P1659-P4238-d21d1ac0-0\tP10\tP1659\tP4238\tnormal\twikibase-property\n",
      "P10-P1659-P51-86aca4c5-0\tP10\tP1659\tP51\tnormal\twikibase-property\n",
      "P10-P1855-Q15075950-7eff6d65-0\tP10\tP1855\tQ15075950\tnormal\twikibase-item\n",
      "P10-P1855-Q4504-a69d2c73-0\tP10\tP1855\tQ4504\tnormal\twikibase-item\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat {claims} | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-03 18:05:25 sqlstore]: IMPORT graph directly into table graph_1 from /data/amandeep/wikidata-20210215/claims.tsv.gz ...\n",
      "[2021-03-03 18:47:35 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT *\n",
      "     FROM graph_1 AS graph_1_c1\n",
      "     LIMIT ?\n",
      "  PARAS: [10]\n",
      "---------------------------------------------\n",
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "P10-P1628-32b85d-7927ece6-0\tP10\tP1628\t\"http://www.w3.org/2006/vcard/ns#Video\"\tnormal\turl\n",
      "P10-P1628-acf60d-b8950832-0\tP10\tP1628\t\"https://schema.org/video\"\tnormal\turl\n",
      "P10-P1629-Q34508-bcc39400-0\tP10\tP1629\tQ34508\tnormal\twikibase-item\n",
      "P10-P1659-P1651-c4068028-0\tP10\tP1659\tP1651\tnormal\twikibase-property\n",
      "P10-P1659-P18-5e4b9c4f-0\tP10\tP1659\tP18\tnormal\twikibase-property\n",
      "P10-P1659-P4238-d21d1ac0-0\tP10\tP1659\tP4238\tnormal\twikibase-property\n",
      "P10-P1659-P51-86aca4c5-0\tP10\tP1659\tP51\tnormal\twikibase-property\n",
      "P10-P1855-Q15075950-7eff6d65-0\tP10\tP1855\tQ15075950\tnormal\twikibase-item\n",
      "P10-P1855-Q4504-a69d2c73-0\tP10\tP1855\tQ4504\tnormal\twikibase-item\n",
      "P10-P1855-Q69063653-c8cdb04c-0\tP10\tP1855\tQ69063653\tnormal\twikibase-item\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {claims} \\\n",
    "--match '()-[]->()' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of all the items we want to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the items to be removed\n",
    "\n",
    "First look at the classes we will remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90mid\u001b[39m Q13442814\n",
      "\u001b[42mLabel\u001b[49m scholarly article\n",
      "\u001b[44mDescription\u001b[49m article in an academic publication, usually peer reviewed\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mscientific publication \u001b[90m(Q591041)\u001b[39m | article \u001b[90m(Q191067)\u001b[39m | scholarly work \u001b[90m(Q55915575)\u001b[39m\n",
      "\n",
      "\u001b[90mid\u001b[39m Q523\n",
      "\u001b[42mLabel\u001b[49m star\n",
      "\u001b[44mDescription\u001b[49m astronomical object consisting of a luminous spheroid of plasma held together by its own gravity\n",
      "\u001b[30m\u001b[47minstance of\u001b[49m\u001b[39m \u001b[90m(P31)\u001b[39m\u001b[90m: \u001b[39m astronomical object type \u001b[90m(Q17444909)\u001b[39m\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mastronomical object \u001b[90m(Q6999)\u001b[39m | fusor \u001b[90m(Q1027098)\u001b[39m\n",
      "\n",
      "\u001b[90mid\u001b[39m Q318\n",
      "\u001b[42mLabel\u001b[49m galaxy\n",
      "\u001b[44mDescription\u001b[49m astronomical structure\n",
      "\u001b[30m\u001b[47minstance of\u001b[49m\u001b[39m \u001b[90m(P31)\u001b[39m\u001b[90m: \u001b[39m astronomical object type \u001b[90m(Q17444909)\u001b[39m\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mdeep-sky object \u001b[90m(Q249389)\u001b[39m\n",
      "\n",
      "\u001b[90mid\u001b[39m Q7318358\n",
      "\u001b[42mLabel\u001b[49m review article\n",
      "\u001b[44mDescription\u001b[49m article that summarizes the current state of understanding on a topic\n",
      "\u001b[30m\u001b[47minstance of\u001b[49m\u001b[39m \u001b[90m(P31)\u001b[39m\u001b[90m: \u001b[39m genre \u001b[90m(Q483394)\u001b[39m\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mscholarly article \u001b[90m(Q13442814)\u001b[39m | secondary source \u001b[90m(Q905511)\u001b[39m\n",
      "\n",
      "\u001b[90mid\u001b[39m Q7187\n",
      "\u001b[42mLabel\u001b[49m gene\n",
      "\u001b[44mDescription\u001b[49m basic physical and functional unit of heredity\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mnucleic acid sequence \u001b[90m(Q863908)\u001b[39m | biological region \u001b[90m(Q50365914)\u001b[39m | biological sequence \u001b[90m(Q3511065)\u001b[39m\n",
      "\n",
      "\u001b[90mid\u001b[39m Q11173\n",
      "\u001b[42mLabel\u001b[49m chemical compound\n",
      "\u001b[44mDescription\u001b[49m pure chemical substance consisting of two or more different chemical elements\n",
      "\u001b[30m\u001b[47minstance of\u001b[49m\u001b[39m \u001b[90m(P31)\u001b[39m\u001b[90m: \u001b[39m group or class of chemical substances \u001b[90m(Q17339814)\u001b[39m | second-order class \u001b[90m(Q24017414)\u001b[39m\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mpure substance \u001b[90m(Q578779)\u001b[39m | chemical component \u001b[90m(Q20026787)\u001b[39m\n",
      "\n",
      "\u001b[90mid\u001b[39m Q8054\n",
      "\u001b[42mLabel\u001b[49m protein\n",
      "\u001b[44mDescription\u001b[49m biological molecule consisting of chains of amino acid residues\n",
      "\u001b[30m\u001b[47minstance of\u001b[49m\u001b[39m \u001b[90m(P31)\u001b[39m\u001b[90m: \u001b[39m group or class of chemical substances \u001b[90m(Q17339814)\u001b[39m | second-order class \u001b[90m(Q24017414)\u001b[39m\n",
      "\u001b[30m\u001b[47msubclass of\u001b[49m\u001b[39m \u001b[90m(P279)\u001b[39m\u001b[90m: \u001b[39mbiopolymer \u001b[90m(Q422649)\u001b[39m | nutrient \u001b[90m(Q181394)\u001b[39m | gene product \u001b[90m(Q424689)\u001b[39m | polyamide \u001b[90m(Q145273)\u001b[39m | biological macromolecule \u001b[90m(Q66560214)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "cmd = \"wd u {}\".format(\" \".join(remove_classes.split(\",\")))\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the kypher command to remove the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1\tlabel\tnode2\n",
      "\n",
      "gzip: P10\tisa\tQ18610173\n",
      "stdout: Broken pipe\n",
      "P1000\tisa\tQ18608871\n",
      "P1001\tisa\tQ15720608\n",
      "P1001\tisa\tQ22984026\n",
      "P1001\tisa\tQ22997934\n",
      "P1001\tisa\tQ61719275\n",
      "P1001\tisa\tQ70564278\n",
      "P1002\tisa\tQ22963600\n",
      "P1003\tisa\tQ19595382\n"
     ]
    }
   ],
   "source": [
    "!zcat < {isa} | head | col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command, the items to remove will be in file `{temp}/items.remove.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-03 18:49:10 sqlstore]: IMPORT graph directly into table graph_2 from /data/amandeep/wikidata-20210215/derived.isa.tsv.gz ...\n",
      "[2021-03-03 18:50:26 sqlstore]: IMPORT graph directly into table graph_3 from /data/amandeep/wikidata-20210215/derived.P279star.tsv.gz ...\n",
      "[2021-03-03 18:52:29 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_2_c1.\"node1\", ? \"_aLias.label\", graph_3_c2.\"node2\" \"_aLias.node2\"\n",
      "     FROM graph_2 AS graph_2_c1, graph_3 AS graph_3_c2\n",
      "     WHERE graph_2_c1.\"label\"=?\n",
      "     AND graph_2_c1.\"node2\"=graph_3_c2.\"node1\"\n",
      "     AND (graph_3_c2.\"node2\" IN (?, ?, ?, ?, ?, ?, ?))\n",
      "  PARAS: ['p31_p279star', 'isa', 'Q13442814', 'Q523', 'Q318', 'Q7318358', 'Q7187', 'Q11173', 'Q8054']\n",
      "---------------------------------------------\n",
      "[2021-03-03 18:52:29 sqlstore]: CREATE INDEX on table graph_2 column node2 ...\n",
      "[2021-03-03 18:53:42 sqlstore]: ANALYZE INDEX on table graph_2 column node2 ...\n",
      "[2021-03-03 18:53:49 sqlstore]: CREATE INDEX on table graph_2 column label ...\n",
      "[2021-03-03 18:54:26 sqlstore]: ANALYZE INDEX on table graph_2 column label ...\n",
      "[2021-03-03 18:54:32 sqlstore]: CREATE INDEX on table graph_3 column node1 ...\n",
      "[2021-03-03 18:55:13 sqlstore]: ANALYZE INDEX on table graph_3 column node1 ...\n"
     ]
    }
   ],
   "source": [
    "classes = \", \".join(list(map(lambda x: '\"{}\"'.format(x), remove_classes.replace(\" \", \"\").split(\",\"))))\n",
    "!{kypher}  -i {isa} -i {p279star} -o {temp}/items.remove.tsv.gz \\\n",
    "--match 'isa: (n1)-[:isa]->(c), P279star: (c)-[]->(class)' \\\n",
    "--where 'class in [{classes}]' \\\n",
    "--return 'distinct n1, \"p31_p279star\" as label, class as node2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1\tlabel\tnode2\n",
      "Q100000005\tp31_p279star\tQ13442814\n",
      "\n",
      "gzip: Q100000009\tp31_p279star\tQ13442814\n",
      "stdout: Broken pipe\n",
      "Q100000015\tp31_p279star\tQ13442814\n",
      "Q100000022\tp31_p279star\tQ13442814\n",
      "Q100000031\tp31_p279star\tQ13442814\n",
      "Q100000044\tp31_p279star\tQ13442814\n",
      "Q100000056\tp31_p279star\tQ13442814\n",
      "Q100000066\tp31_p279star\tQ13442814\n",
      "Q100000074\tp31_p279star\tQ13442814\n"
     ]
    }
   ],
   "source": [
    "!zcat < {temp}/items.remove.tsv.gz | head | col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50813634 152440902 1624655207\n"
     ]
    }
   ],
   "source": [
    "!zcat < {temp}/items.remove.tsv.gz | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {temp}/items.remove.tsv.gz | grep 'Q502268\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {temp}/items.remove.tsv.gz | grep 'Q15874936\\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the classes of items we will remove, just as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-03 19:11:08 sqlstore]: IMPORT graph directly into table graph_4 from /data/amandeep/temp.wikidata-20210215-dwd/items.remove.tsv.gz ...\n",
      "[2021-03-03 19:11:52 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_4_c1.\"node2\"\n",
      "     FROM graph_4 AS graph_4_c1\n",
      "     LIMIT ?\n",
      "  PARAS: [10]\n",
      "---------------------------------------------\n",
      "node2\n",
      "Q13442814\n",
      "Q7187\n",
      "Q11173\n",
      "Q8054\n",
      "Q523\n",
      "Q7318358\n",
      "Q318\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {temp}/items.remove.tsv.gz \\\n",
    "--match '()-[]->(n2)' \\\n",
    "--return 'distinct n2' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced edges file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the items from the all.tsv and the label, alias and description files\n",
    "We will be left with `reduced` files where the edges do not have the unwanted items. We have to remove them from the node1 and node2 positions, so we need to run the ifnotexists commands twice.\n",
    "\n",
    "Before we start preview the files to see the column headings and check whether they look sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m54.884s\n",
      "user\t0m56.043s\n",
      "sys\t0m6.135s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk sort2 -i {temp}/items.remove.tsv.gz -o {temp}/items.remove.sorted.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1\tlabel\tnode2\n",
      "Q100000005\tp31_p279star\tQ13442814\n",
      "Q100000009\tp31_p279star\tQ13442814\n",
      "Q100000015\tp31_p279star\tQ13442814\n",
      "Q100000022\tp31_p279star\tQ13442814\n",
      "Q100000031\tp31_p279star\tQ13442814\n",
      "Q100000044\tp31_p279star\tQ13442814\n",
      "Q100000056\tp31_p279star\tQ13442814\n",
      "Q100000066\tp31_p279star\tQ13442814\n",
      "\n",
      "gzip: Q100000074\tp31_p279star\tQ13442814\n",
      "stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < {temp}/items.remove.sorted.tsv.gz | head | col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "P10-P1628-32b85d-7927ece6-0\tP10\tP1628\t\"http://www.w3.org/2006/vcard/ns#Video\" normal\turl\n",
      "P10-P1628-acf60d-b8950832-0\tP10\tP1628\t\"https://schema.org/video\"\tnormal\turl\n",
      "P10-P1629-Q34508-bcc39400-0\tP10\tP1629\tQ34508\tnormal\twikibase-item\n",
      "P10-P1659-P1651-c4068028-0\tP10\tP1659\tP1651\tnormal\twikibase-property\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < \"{claims}\" | head -5 | col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove from the full set of edges those edges that have a `node1` present in `items.remove.sorted.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t134m45.951s\n",
      "user\t134m26.898s\n",
      "sys\t0m18.649s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk ifnotexists -i \"{claims}\" -o {temp}/item.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the remaining edges, remove those that have a `node2` present in `items.remove.sorted.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t31m44.772s\n",
      "user\t33m46.173s\n",
      "sys\t2m6.857s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk sort2 -i {temp}/item.edges.reduced.tsv.gz -o {temp}/item.edges.reduced.sorted.tsv.gz \\\n",
    "--columns node2 label node1 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t83m19.639s\n",
      "user\t83m7.751s\n",
      "sys\t0m7.814s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk ifnotexists -i {temp}/item.edges.reduced.sorted.tsv.gz -o {temp}/item.edges.reduced.2.tsv.gz \\\n",
    "--filter-on {temp}/items.remove.sorted.tsv.gz \\\n",
    "--input-keys node2 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the labels, for all the languages specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    cmd = f\"kgtk --debug ifnotexists -i {wiki_root_folder}labels.{lang}.tsv.gz \\\n",
    "    -o {temp}/label.{lang}.edges.reduced.tsv.gz \\\n",
    "    --filter-on {temp}/items.remove.sorted.tsv.gz \\\n",
    "    --input-keys node1 \\\n",
    "    --filter-keys node1 \\\n",
    "    --presorted\"\n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    cmd = f\"kgtk sort2 -i {temp}/label.{lang}.edges.reduced.tsv.gz -o {out}/labels.{lang}.tsv.gz\" \n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the aliases, for all the languages specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    cmd = f\"kgtk --debug ifnotexists -i {wiki_root_folder}aliases.{lang}.tsv.gz \\\n",
    "    -o {temp}/alias.{lang}.edges.reduced.tsv.gz \\\n",
    "    --filter-on {temp}/items.remove.sorted.tsv.gz \\\n",
    "    --input-keys node1 \\\n",
    "    --filter-keys node1 \\\n",
    "    --presorted\"\n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    cmd = f\"kgtk sort2 -i {temp}/alias.{lang}.edges.reduced.tsv.gz -o {out}/aliases.{lang}.tsv.gz\" \n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the descriptions, for all the languages specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    cmd = f\"kgtk --debug ifnotexists -i {wiki_root_folder}descriptions.{lang}.tsv.gz \\\n",
    "    -o {temp}/description.{lang}.edges.reduced.tsv.gz \\\n",
    "    --filter-on {temp}/items.remove.sorted.tsv.gz \\\n",
    "    --input-keys node1 \\\n",
    "    --filter-keys node1 \\\n",
    "    --presorted\"\n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    cmd = f\"kgtk sort2 -i {temp}/description.{lang}.edges.reduced.tsv.gz -o {out}/descriptions.{lang}.tsv.gz\" \n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce the output files for claims, labels, aliases and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t30m39.899s\n",
      "user\t31m21.509s\n",
      "sys\t2m31.669s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk sort2 -i {temp}/item.edges.reduced.2.tsv.gz -o {out}/claims.tsv.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced qualifiers file\n",
    "We do this by finding all the ids of the reduced edges file, and then selecting out from `qual.tsv`\n",
    "\n",
    "We need to join by id, so we need to sort both files by id, node1, label, node2:\n",
    "\n",
    "- `{quals}` \n",
    "- `{out}/claims.tsv.gz` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                node1                           label  node2                                                                    node2;wikidatatype\n",
      "P10-P1855-Q15075950-7eff6d65-0-P10-54b214-0       P10-P1855-Q15075950-7eff6d65-0  P10    \"Smoorverliefd 12 september.webm\"                                        commonsMedia\n",
      "P10-P1855-Q15075950-7eff6d65-0-P3831-Q622550-0    P10-P1855-Q15075950-7eff6d65-0  P3831  Q622550                                                                  wikibase-item\n",
      "P10-P1855-Q4504-a69d2c73-0-P10-bef003-0           P10-P1855-Q4504-a69d2c73-0      P10    \"Komodo dragons video.ogv\"                                               commonsMedia\n",
      "P10-P1855-Q69063653-c8cdb04c-0-P10-6fb08f-0       P10-P1855-Q69063653-c8cdb04c-0  P10    \"Couch Commander.webm\"                                                   commonsMedia\n",
      "P10-P1855-Q7378-555592a4-0-P10-8a982d-0           P10-P1855-Q7378-555592a4-0      P10    \"Elephants Dream (2006).webm\"                                            commonsMedia\n",
      "P10-P2302-Q21502404-d012aef4-0-P1793-f4c2ed-0     P10-P2302-Q21502404-d012aef4-0  P1793  \"(?i).+\\\\.(webm\\|ogv\\|ogg\\|gif)\"                                         string\n",
      "P10-P2302-Q21502404-d012aef4-0-P2316-Q21502408-0  P10-P2302-Q21502404-d012aef4-0  P2316  Q21502408                                                                wikibase-item\n",
      "P10-P2302-Q21502404-d012aef4-0-P2916-cb0917-0     P10-P2302-Q21502404-d012aef4-0  P2916  'filename with extension: webm, ogg, ogv, or gif (case insensitive)'@en  monolingualtext\n",
      "P10-P2302-Q21510851-5224fe0b-0-P2306-P175-0       P10-P2302-Q21510851-5224fe0b-0  P2306  P175                                                                     wikibase-property\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < \"{quals}\" | head | column -t -s $'\\t' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `ifexists` to select out the quals for the edges in `{out}/wikidataos.qual.tsv.gz`. Note that we use `node1` in the qualifier file, matching to `id` in the `wikidataos.all.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t49m25.596s\n",
      "user\t49m17.469s\n",
      "sys\t0m7.472s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk ifexists -i \"{quals}\" -o {out}/qualifiers.tsv.gz \\\n",
    "--filter-on {out}/claims.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys id \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the final output for qualifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tnode1\tlabel\tnode2\tnode2;wikidatatype\n",
      "P10-P1855-Q15075950-7eff6d65-0-P10-54b214-0\tP10-P1855-Q15075950-7eff6d65-0\tP10\t\"Smoorverliefd 12 september.webm\"\tcommonsMedia\n",
      "P10-P1855-Q15075950-7eff6d65-0-P3831-Q622550-0\tP10-P1855-Q15075950-7eff6d65-0\tP3831\tQ622550 wikibase-item\n",
      "P10-P1855-Q4504-a69d2c73-0-P10-bef003-0 P10-P1855-Q4504-a69d2c73-0\tP10\t\"Komodo dragons video.ogv\"\tcommonsMedia\n",
      "P10-P1855-Q69063653-c8cdb04c-0-P10-6fb08f-0\tP10-P1855-Q69063653-c8cdb04c-0\tP10\t\"Couch Commander.webm\"\tcommonsMedia\n",
      "P10-P1855-Q7378-555592a4-0-P10-8a982d-0 P10-P1855-Q7378-555592a4-0\tP10\t\"Elephants Dream (2006).webm\"\tcommonsMedia\n",
      "P10-P2302-Q21502404-d012aef4-0-P1793-f4c2ed-0\tP10-P2302-Q21502404-d012aef4-0\tP1793\t\"(?i).+\\\\.(webm\\|ogv\\|ogg\\|gif)\"\tstring\n",
      "P10-P2302-Q21502404-d012aef4-0-P2316-Q21502408-0\tP10-P2302-Q21502404-d012aef4-0\tP2316\tQ21502408\twikibase-item\n",
      "P10-P2302-Q21502404-d012aef4-0-P2916-cb0917-0\tP10-P2302-Q21502404-d012aef4-0\tP2916\t'filename with extension: webm, ogg, ogv, or gif (case insensitive)'@en monolingualtext\n",
      "\n",
      "gzip: P10-P2302-Q21510851-5224fe0b-0-P2306-P175-0\tP10-P2302-Q21510851-5224fe0b-0\tP2306\tP175\twikibase-property\n",
      "stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < {out}/qualifiers.tsv.gz | head | col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias.de.edges.reduced.tsv.gz\t     description.sv.edges.reduced.tsv.gz\n",
      "alias.en.edges.reduced.tsv.gz\t     description.zh-cn.edges.reduced.tsv.gz\n",
      "alias.es.edges.reduced.tsv.gz\t     item.edges.reduced.2.tsv.gz\n",
      "alias.fr.edges.reduced.tsv.gz\t     item.edges.reduced.sorted.tsv.gz\n",
      "alias.it.edges.reduced.tsv.gz\t     item.edges.reduced.tsv.gz\n",
      "alias.nl.edges.reduced.tsv.gz\t     items.remove.sorted.tsv.gz\n",
      "alias.pl.edges.reduced.tsv.gz\t     items.remove.tsv.gz\n",
      "alias.pt.edges.reduced.tsv.gz\t     label.de.edges.reduced.tsv.gz\n",
      "alias.ru.edges.reduced.tsv.gz\t     label.en.edges.reduced.tsv.gz\n",
      "alias.sv.edges.reduced.tsv.gz\t     label.es.edges.reduced.tsv.gz\n",
      "alias.zh-cn.edges.reduced.tsv.gz     label.fr.edges.reduced.tsv.gz\n",
      "description.de.edges.reduced.tsv.gz  label.it.edges.reduced.tsv.gz\n",
      "description.en.edges.reduced.tsv.gz  label.nl.edges.reduced.tsv.gz\n",
      "description.es.edges.reduced.tsv.gz  label.pl.edges.reduced.tsv.gz\n",
      "description.fr.edges.reduced.tsv.gz  label.pt.edges.reduced.tsv.gz\n",
      "description.it.edges.reduced.tsv.gz  label.ru.edges.reduced.tsv.gz\n",
      "description.nl.edges.reduced.tsv.gz  label.sv.edges.reduced.tsv.gz\n",
      "description.pl.edges.reduced.tsv.gz  label.zh-cn.edges.reduced.tsv.gz\n",
      "description.pt.edges.reduced.tsv.gz  wikidata.sqlite3.db\n",
      "description.ru.edges.reduced.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls \"$TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliases.de.tsv.gz     descriptions.de.tsv.gz\t labels.en.tsv.gz\n",
      "aliases.en.tsv.gz     descriptions.en.tsv.gz\t labels.es.tsv.gz\n",
      "aliases.es.tsv.gz     descriptions.es.tsv.gz\t labels.fr.tsv.gz\n",
      "aliases.fr.tsv.gz     descriptions.fr.tsv.gz\t labels.it.tsv.gz\n",
      "aliases.it.tsv.gz     descriptions.it.tsv.gz\t labels.nl.tsv.gz\n",
      "aliases.nl.tsv.gz     descriptions.nl.tsv.gz\t labels.pl.tsv.gz\n",
      "aliases.pl.tsv.gz     descriptions.pl.tsv.gz\t labels.pt.tsv.gz\n",
      "aliases.pt.tsv.gz     descriptions.pt.tsv.gz\t labels.ru.tsv.gz\n",
      "aliases.ru.tsv.gz     descriptions.ru.tsv.gz\t labels.sv.tsv.gz\n",
      "aliases.sv.tsv.gz     descriptions.sv.tsv.gz\t labels.zh-cn.tsv.gz\n",
      "aliases.zh-cn.tsv.gz  descriptions.zh-cn.tsv.gz  qualifiers.tsv.gz\n",
      "claims.tsv.gz\t      labels.de.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls \"$OUT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the property datatypes and metadata types file over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATATYPES\"] = datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $DATATYPES $OUT/metadata.property.datatypes.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out edges from metdata types file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t31m7.984s\n",
      "user\t31m4.925s\n",
      "sys\t0m2.904s\n"
     ]
    }
   ],
   "source": [
    "!$kgtk ifexists -i \"{metadata_types}\" -o {out}/metadata.types.tsv.gz \\\n",
    "--filter-on {out}/claims.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contruct the cat command to generate `all.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "_files = []\n",
    "\n",
    "cat_cmd = \"\"\n",
    "for lang in languages:\n",
    "    _files.append(f\"-i \\\"$OUT\\\"/labels.{lang}.tsv.gz\")\n",
    "    _files.append(f\"-i \\\"$OUT\\\"/aliases.{lang}.tsv.gz\")\n",
    "    _files.append(f\"-i \\\"$OUT\\\"/descriptions.{lang}.tsv.gz\")\n",
    "\n",
    "_files.append(\"-i \\\"$OUT\\\"/qualifiers.tsv.gz\")\n",
    "_files.append(\"-i \\\"$OUT\\\"/claims.tsv.gz\")\n",
    "_files.append(\"-i \\\"$OUT\\\"/metadata.property.datatypes.tsv.gz\")\n",
    "_files.append(\"-i \\\"$OUT\\\"/metadata.types.tsv.gz\")\n",
    "_files.append(\"-o \\\"$OUT\\\"/all.tsv.gz\")\n",
    "\n",
    "cat_command = \"kgtk cat \" + \" \".join(_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TEMP\"] = temp\n",
    "os.environ[\"OUT\"] = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Partitions Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa9aa53412342faaa10df409ab23782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.execute_notebook(\n",
    "    os.environ[\"EXAMPLES_DIR\"] + \"/partition-wikidata.ipynb\",\n",
    "    os.environ[\"TEMP\"] + \"/partition-wikidata.out.ipynb\",\n",
    "    parameters=dict(\n",
    "        wikidata_input_path = os.environ[\"OUT\"] + \"/all.tsv.gz\",\n",
    "        wikidata_parts_path = os.environ[\"OUT\"] + \"/parts\",\n",
    "        temp_folder_path = os.environ[\"OUT\"] + \"/parts/temp\",\n",
    "        sort_extras = \"--buffer-size 30% --temporary-directory $OUT/parts/temp\",\n",
    "        verbose = False,\n",
    "        gzip_command = 'gzip'\n",
    "    )\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy the `claims.wikibase-item.tsv` file from the `parts` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $OUT/parts/claims.wikibase-item.tsv.gz $OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN the Useful Files notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90131acba7c348f2bd79472c88ed0e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Executing'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [63]\":\n---------------------------------------------------------------------------\nMaxRowsError                              Traceback (most recent call last)\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/vegalite/v4/api.py in to_dict(self, *args, **kwargs)\n    361         copy = self.copy(deep=False)\n    362         original_data = getattr(copy, \"data\", Undefined)\n--> 363         copy.data = _prepare_data(original_data, context)\n    364 \n    365         if original_data is not Undefined:\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/vegalite/v4/api.py in _prepare_data(data, context)\n     82     # convert dataframes  or objects with __geo_interface__ to dict\n     83     if isinstance(data, pd.DataFrame) or hasattr(data, \"__geo_interface__\"):\n---> 84         data = _pipe(data, data_transformers.get())\n     85 \n     86     # convert string input to a URLData\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in pipe(data, *funcs)\n    625     \"\"\"\n    626     for func in funcs:\n--> 627         data = func(data)\n    628     return data\n    629 \n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in __call__(self, *args, **kwargs)\n    301     def __call__(self, *args, **kwargs):\n    302         try:\n--> 303             return self._partial(*args, **kwargs)\n    304         except TypeError as exc:\n    305             if self._should_curry(args, kwargs, exc):\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/vegalite/data.py in default_data_transformer(data, max_rows)\n     17 @curried.curry\n     18 def default_data_transformer(data, max_rows=5000):\n---> 19     return curried.pipe(data, limit_rows(max_rows=max_rows), to_values)\n     20 \n     21 \n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in pipe(data, *funcs)\n    625     \"\"\"\n    626     for func in funcs:\n--> 627         data = func(data)\n    628     return data\n    629 \n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in __call__(self, *args, **kwargs)\n    301     def __call__(self, *args, **kwargs):\n    302         try:\n--> 303             return self._partial(*args, **kwargs)\n    304         except TypeError as exc:\n    305             if self._should_curry(args, kwargs, exc):\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/utils/data.py in limit_rows(data, max_rows)\n     82             \"than the maximum allowed ({}). \"\n     83             \"For information on how to plot larger datasets \"\n---> 84             \"in Altair, see the documentation\".format(max_rows)\n     85         )\n     86     return data\n\nMaxRowsError: The number of rows in your dataset is greater than the maximum allowed (5000). For information on how to plot larger datasets in Altair, see the documentation\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fdf46bdfebc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcompute_pagerank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdelete_database\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/papermill/execute.py\u001b[0m in \u001b[0;36mexecute_notebook\u001b[0;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# Check for errors first (it saves on error before raising)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mraise_for_execution_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Write final output in case the engine didn't write it on cell completion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/papermill/execute.py\u001b[0m in \u001b[0;36mraise_for_execution_errors\u001b[0;34m(nb, output_path)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mwrite_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [63]\":\n---------------------------------------------------------------------------\nMaxRowsError                              Traceback (most recent call last)\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/vegalite/v4/api.py in to_dict(self, *args, **kwargs)\n    361         copy = self.copy(deep=False)\n    362         original_data = getattr(copy, \"data\", Undefined)\n--> 363         copy.data = _prepare_data(original_data, context)\n    364 \n    365         if original_data is not Undefined:\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/vegalite/v4/api.py in _prepare_data(data, context)\n     82     # convert dataframes  or objects with __geo_interface__ to dict\n     83     if isinstance(data, pd.DataFrame) or hasattr(data, \"__geo_interface__\"):\n---> 84         data = _pipe(data, data_transformers.get())\n     85 \n     86     # convert string input to a URLData\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in pipe(data, *funcs)\n    625     \"\"\"\n    626     for func in funcs:\n--> 627         data = func(data)\n    628     return data\n    629 \n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in __call__(self, *args, **kwargs)\n    301     def __call__(self, *args, **kwargs):\n    302         try:\n--> 303             return self._partial(*args, **kwargs)\n    304         except TypeError as exc:\n    305             if self._should_curry(args, kwargs, exc):\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/vegalite/data.py in default_data_transformer(data, max_rows)\n     17 @curried.curry\n     18 def default_data_transformer(data, max_rows=5000):\n---> 19     return curried.pipe(data, limit_rows(max_rows=max_rows), to_values)\n     20 \n     21 \n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in pipe(data, *funcs)\n    625     \"\"\"\n    626     for func in funcs:\n--> 627         data = func(data)\n    628     return data\n    629 \n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/toolz/functoolz.py in __call__(self, *args, **kwargs)\n    301     def __call__(self, *args, **kwargs):\n    302         try:\n--> 303             return self._partial(*args, **kwargs)\n    304         except TypeError as exc:\n    305             if self._should_curry(args, kwargs, exc):\n\n/opt/miniconda3/envs/kgtk-env/lib/python3.7/site-packages/altair/utils/data.py in limit_rows(data, max_rows)\n     82             \"than the maximum allowed ({}). \"\n     83             \"For information on how to plot larger datasets \"\n---> 84             \"in Altair, see the documentation\".format(max_rows)\n     85         )\n     86     return data\n\nMaxRowsError: The number of rows in your dataset is greater than the maximum allowed (5000). For information on how to plot larger datasets in Altair, see the documentation\n"
     ]
    }
   ],
   "source": [
    "pm.execute_notebook(\n",
    "    os.environ[\"USECASE_DIR\"] + \"/Wikidata Useful Files.ipynb\",\n",
    "    os.environ[\"TEMP\"] + \"/Wikidata Useful Files Out.ipynb\",\n",
    "    parameters=dict(\n",
    "        output_path = os.environ[\"OUT\"],\n",
    "        output_folder = \"useful_files\",\n",
    "        temp_folder = \"temp.useful_files\",\n",
    "        wiki_root_folder = os.environ[\"OUT\"] + \"/parts/\",\n",
    "        cache_path = os.environ[\"OUT\"] + \"/temp.useful_files\",\n",
    "        languages = 'en',\n",
    "        compute_pagerank = True,\n",
    "        delete_database = False\n",
    "    )\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-06 14:52:07 sqlstore]: IMPORT graph directly into table graph_5 from /data/amandeep/wikidata-20210215-dwd/claims.tsv.gz ...\n",
      "[2021-03-06 15:02:12 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT *\n",
      "     FROM graph_5 AS graph_5_c1\n",
      "     WHERE graph_5_c1.\"node1\"=?\n",
      "     LIMIT ?\n",
      "  PARAS: ['Q368441', 10]\n",
      "---------------------------------------------\n",
      "[2021-03-06 15:02:12 sqlstore]: CREATE INDEX on table graph_5 column node1 ...\n",
      "[2021-03-06 15:05:15 sqlstore]: ANALYZE INDEX on table graph_5 column node1 ...\n",
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "Q368441-P106-Q937857-ba9afa6b-0 Q368441 P106\tQ937857 normal\twikibase-item\n",
      "Q368441-P109-358e4e-63970f77-0\tQ368441 P109\t\"James Rodriguez Signature.svg\" normal\tcommonsMedia\n",
      "Q368441-P118-Q82595-62cd72d9-0\tQ368441 P118\tQ82595\tnormal\twikibase-item\n",
      "Q368441-P1344-Q170645-3f2d9c6a-0\tQ368441 P1344\tQ170645 normal\twikibase-item\n",
      "Q368441-P1344-Q4630358-8e287039-0\tQ368441 P1344\tQ4630358\tnormal\twikibase-item\n",
      "Q368441-P1344-Q79859-b4aa617a-0 Q368441 P1344\tQ79859\tnormal\twikibase-item\n",
      "Q368441-P1350-311711-c4586257-0 Q368441 P1350\t+2\tnormal\tquantity\n",
      "Q368441-P1350-311711-e8a428a4-0 Q368441 P1350\t+2\tnormal\tquantity\n",
      "Q368441-P1412-Q1321-1ea511cf-0\tQ368441 P1412\tQ1321\tnormal\twikibase-item\n",
      "Q368441-P1469-db16a0-ef899f25-0 Q368441 P1469\t\"269058\"\tnormal\texternal-id\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {out}/claims.tsv.gz \\\n",
    "--match '(n1:Q368441)-[l]->(n2)' \\\n",
    "--limit 10 \\\n",
    "| col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-06 15:05:40 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT *\n",
      "     FROM graph_5 AS graph_5_c1\n",
      "     WHERE graph_5_c1.\"node1\"=?\n",
      "     LIMIT ?\n",
      "  PARAS: ['P131', 10]\n",
      "---------------------------------------------\n",
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "P131-P1628-951146-4681d72b-0\tP131\tP1628\t\"http://dati.beniculturali.it/cis/GovernamentalAdministrativeArea\"\tnormal\turl\n",
      "P131-P1629-Q56061-0d5b0586-0\tP131\tP1629\tQ56061\tnormal\twikibase-item\n",
      "P131-P1647-P276-5cc63556-0\tP131\tP1647\tP276\tnormal\twikibase-property\n",
      "P131-P1647-P361-257a2660-0\tP131\tP1647\tP361\tnormal\twikibase-property\n",
      "P131-P1659-P1001-f0f7e26a-0\tP131\tP1659\tP1001\tnormal\twikibase-property\n",
      "P131-P1659-P1383-3ebd92d5-0\tP131\tP1659\tP1383\tnormal\twikibase-property\n",
      "P131-P1659-P150-d414f410-0\tP131\tP1659\tP150\tnormal\twikibase-property\n",
      "P131-P1659-P159-e71dc93e-0\tP131\tP1659\tP159\tnormal\twikibase-property\n",
      "P131-P1659-P17-bbd89dc1-0\tP131\tP1659\tP17\tnormal\twikibase-property\n",
      "P131-P1659-P206-7eb31568-0\tP131\tP1659\tP206\tnormal\twikibase-property\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {out}/claims.tsv.gz \\\n",
    "--match '(n1:P131)-[l]->(n2)' \\\n",
    "--limit 10 \\\n",
    "| col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 amandeep isdstaff  32M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.de.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  81M Mar  4 01:20 /data/amandeep/wikidata-20210215-dwd/aliases.en.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  24M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.es.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  27M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.fr.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  13M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.it.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  25M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.nl.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 6.7M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.pl.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 9.2M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.pt.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  35M Mar  4 01:20 /data/amandeep/wikidata-20210215-dwd/aliases.ru.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 7.6M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.sv.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 5.3M Mar  4 01:21 /data/amandeep/wikidata-20210215-dwd/aliases.zh-cn.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  11G Mar  4 13:23 /data/amandeep/wikidata-20210215-dwd/all.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 6.2G Mar  4 03:26 /data/amandeep/wikidata-20210215-dwd/claims.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 2.6G Mar  5 10:01 /data/amandeep/wikidata-20210215-dwd/claims.wikibase-item.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 212M Mar  4 02:52 /data/amandeep/wikidata-20210215-dwd/descriptions.de.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 322M Mar  4 02:50 /data/amandeep/wikidata-20210215-dwd/descriptions.en.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 127M Mar  4 02:51 /data/amandeep/wikidata-20210215-dwd/descriptions.es.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 156M Mar  4 02:55 /data/amandeep/wikidata-20210215-dwd/descriptions.fr.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 107M Mar  4 02:53 /data/amandeep/wikidata-20210215-dwd/descriptions.it.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 238M Mar  4 02:54 /data/amandeep/wikidata-20210215-dwd/descriptions.nl.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  65M Mar  4 02:54 /data/amandeep/wikidata-20210215-dwd/descriptions.pl.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  86M Mar  4 02:55 /data/amandeep/wikidata-20210215-dwd/descriptions.pt.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  86M Mar  4 02:50 /data/amandeep/wikidata-20210215-dwd/descriptions.ru.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  75M Mar  4 02:56 /data/amandeep/wikidata-20210215-dwd/descriptions.sv.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  46M Mar  4 02:51 /data/amandeep/wikidata-20210215-dwd/descriptions.zh-cn.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 164M Mar  4 00:44 /data/amandeep/wikidata-20210215-dwd/labels.de.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 460M Mar  4 00:42 /data/amandeep/wikidata-20210215-dwd/labels.en.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 172M Mar  4 00:44 /data/amandeep/wikidata-20210215-dwd/labels.es.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 173M Mar  4 00:47 /data/amandeep/wikidata-20210215-dwd/labels.fr.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 118M Mar  4 00:45 /data/amandeep/wikidata-20210215-dwd/labels.it.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 246M Mar  4 00:46 /data/amandeep/wikidata-20210215-dwd/labels.nl.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  87M Mar  4 00:46 /data/amandeep/wikidata-20210215-dwd/labels.pl.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 100M Mar  4 00:47 /data/amandeep/wikidata-20210215-dwd/labels.pt.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 102M Mar  4 00:43 /data/amandeep/wikidata-20210215-dwd/labels.ru.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  96M Mar  4 00:47 /data/amandeep/wikidata-20210215-dwd/labels.sv.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  12M Mar  4 00:44 /data/amandeep/wikidata-20210215-dwd/labels.zh-cn.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff  47K Mar  4 09:24 /data/amandeep/wikidata-20210215-dwd/metadata.property.datatypes.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 197M Mar  4 10:01 /data/amandeep/wikidata-20210215-dwd/metadata.types.tsv.gz\n",
      "-rw-r--r-- 1 amandeep isdstaff 883M Mar  4 09:00 /data/amandeep/wikidata-20210215-dwd/qualifiers.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {out}/*.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad = []\n",
    "if 'en' not in languages:\n",
    "    languages.append('en')\n",
    "for lang in languages:\n",
    "    lad.append(f\"{out}/labels.{lang}.tsv.gz\")\n",
    "    lad.append(f\"{out}/aliases.{lang}.tsv.gz\")\n",
    "    lad.append(f\"{out}/descriptions.{lang}.tsv.gz\")\n",
    "lad_file_list = \" \".join(lad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk cat -i {out}/claims.tsv.gz \\\n",
    "{lad_file_list} \\\n",
    "{out}/qualifiers.tsv.gz \\\n",
    "{out}/useful_files/metadata.pagerank.undirected.tsv.gz \\\n",
    "{out}/useful_files/metadata.pagerank.directed.tsv.gz \\\n",
    "{out}/useful_files/metadata.in_degree.tsv.gz \\\n",
    "{out}/useful_files/metadata.out_degree.tsv.gz \\\n",
    "-o {out}/wikidatadwd.all.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all for triples` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk cat -i $OUT/wikidatadwd.all.tsv.gz \\\n",
    "$OUT/useful_files/derived.isa.tsv.gz \\\n",
    "$OUT/useful_files/derived.P279star.tsv.gz \\\n",
    "-o $OUT/wikidatadwd.all.for.triples.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all for elasticsearch` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk cat -i $OUT/wikidatadwd.all.tsv.gz \\\n",
    "$OUT/useful_files/derived.P279.tsv.gz \\\n",
    "$OUT/useful_files/derived.isastar.tsv.gz \\\n",
    "-o $OUT/wikidatadwd.all.for.es.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove `somevalue,novalue,P9`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this might not be needed in future: AS (03/11/2021)\n",
    "!kgtk filter -i $OUT/wikidatadwd.all.for.es.tsv.gz \\\n",
    "    -o $OUT/wikidataos.all.for.es.filtered.tsv.gz \\\n",
    "    -p ';;somevalue,novalue,P9' --invert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add text and graph embeddings, augmented wikipedia and abbreviated human names for ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk cat \\\n",
    "-i $OUT/wikidatadwd.all.for.es.tsv.gz \\\n",
    "-i $OUT/metadata.property.datatypes.tsv.gz \\\n",
    "-i $OUT/graph-embeddings/wikidataos.complEx.graph-embeddings.tsv.gz \\\n",
    "-i $OUT/graph-embeddings/wikidataos.transE.graph-embeddings.tsv.gz \\\n",
    "-i $OUT/text-embeddings/text-embeddings-concatenated.tsv.gz \\\n",
    "-i $OUT/derived_files_for_es/augmentation.wikipedia.anchors.tsv.gz \\\n",
    "-i $OUT/derived_files_for_es/augmentation.wikipedia.redirect.tsv.gz \\\n",
    "-i $OUT/derived_files_for_es/augmentation.wikipedia.tables.anchors.tsv.gz \\\n",
    "-i $OUT/derived_files_for_es/derived.Q5.abbreviations.tsv.gz \\\n",
    "-o $OUT/wikidatadwd.all.for.es.embeddings.augmented.unsorted.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove columns `id rank node2;wikidatatype url` as it is not required in the ES file and then sort the file by `node1,label`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!kgtk remove-columns --columns id,rank,node2;wikidatatype,url \\\n",
    "-i $OUT/wikidatadwd.all.for.es.embeddings.augmented.unsorted.tsv.gz \\\n",
    "-o $OUT/wikidatadwd.all.for.es.embeddings.augmented.unsorted.clean.tsv.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/amandeep/temp.wikidata-20210215-dwd'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk sort -c node1,label \\\n",
    "-i $OUT/wikidatadwd.all.for.es.embeddings.augmented.unsorted.tsv.gz \\\n",
    "--extra '--parallel 24 --buffer-size 30% --temporary-directory /data/amandeep/temp.wikidata-20210215-dwd' \\\n",
    "-o $OUT/wikidatadwd.all.for.es.embeddings.augmented.sorted.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out `novalue`, `somevalue` and `P9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk filter -i $OUT/wikidataos.all.for.triples.tsv.gz \\\n",
    "    -o $OUT/wikidataos.all.for.triples.filtered.tsv.gz \\\n",
    "    -p ';;somevalue,novalue,P9' --invert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ids for any edge with missing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk add-id -i $OUT/wikidataos.all.for.triples.filtered.tsv.gz \\\n",
    "-o $OUT/wikidataos.all.for.triples.filtered.id.tsv.gz \\\n",
    "--id-style wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk sort2 -i $OUT/wikidataos.all.for.triples.filtered.id.tsv.gz \\\n",
    "-o $OUT/wikidataos.all.for.triples.filtered.id.sorted.tsv.gz \n",
    "-c id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run graph embeddings: complEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Processing, Please go to /data/amandeep/wikidata-20210215-dwd/graph-embeddings/temp/ge.complex.log to check details\n",
      "Opening the input file: /data/amandeep/wikidata-20210215-dwd/parts/claims.wikibase-item.tsv.gz\n",
      "KgtkReader: File_path.suffix: .gz\n",
      "KgtkReader: reading gzip /data/amandeep/wikidata-20210215-dwd/parts/claims.wikibase-item.tsv.gz\n",
      "header: id\tnode1\tlabel\tnode2\tnode2;wikidatatype\trank\n",
      "input format: kgtk\n",
      "node1 column found, this is a KGTK edge file\n",
      "KgtkReader: Special columns: node1=1 label=2 node2=3 id=0\n",
      "KgtkReader: Reading an edge file.\n",
      "Opening the output file: /data/amandeep/wikidata-20210215-dwd/graph-embeddings/temp/tmp_claims.wikibase-item.tsv.gz\n",
      "File_path.suffix: .gz\n",
      "KgtkWriter: writing gzip /data/amandeep/wikidata-20210215-dwd/graph-embeddings/temp/tmp_claims.wikibase-item.tsv.gz\n",
      "header: id\tnode1\tlabel\tnode2\tnode2;wikidatatype\trank\n",
      "Processing the input records.\n",
      "Processed 182246240 records.\n"
     ]
    }
   ],
   "source": [
    "# make sure the output directories are created\n",
    "!kgtk --debug graph-embeddings --verbose -i $OUT/parts/claims.wikibase-item.tsv.gz \\\n",
    "-o $OUT/graph-embeddings/wikidataos.complEx.graph-embeddings.txt \\\n",
    "--retain_temporary_data True \\\n",
    "--operator ComplEx \\\n",
    "--workers 24 \\\n",
    "--log $OUT/graph-embeddings/temp/ge.complex.log \\\n",
    "-T $OUT/graph-embeddings/temp \\\n",
    "-ot w2v \\\n",
    "-e 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "kgtk-env",
   "language": "python",
   "name": "kgtk-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
